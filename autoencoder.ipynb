{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from pre import Training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: training_data.npy| labels: training_labels.npy\n"
     ]
    }
   ],
   "source": [
    "_AMOUNT_CLASSE = 11\n",
    "training_data = Training_data('training',_AMOUNT_CLASSE)\n",
    "\n",
    "#import the training data\n",
    "_dices = np.load('training_data.npy')\n",
    "labels = np.load('training_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "X_train, X_test, _, _ = train_test_split(_dices,labels,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "input_size = 128\n",
    "filter = 64\n",
    "epochs = 20\n",
    "batchsize = 128\n",
    "\n",
    "\n",
    "strides = (2, 2)\n",
    "pool_size = (2,2)\n",
    "kernel_size = (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " c1 (Conv2D)                 (None, 128, 128, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 64, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " bn1 (BatchNormalization)    (None, 64, 64, 32)        128       \n",
      "                                                                 \n",
      " LR1 (LeakyReLU)             (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " c2 (Conv2D)                 (None, 32, 32, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 16, 16, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " bn2 (BatchNormalization)    (None, 16, 16, 16)        64        \n",
      "                                                                 \n",
      " LR2 (LeakyReLU)             (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " c3 (Conv2D)                 (None, 8, 8, 8)           1160      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 4, 4, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " bn3 (BatchNormalization)    (None, 4, 4, 8)           32        \n",
      "                                                                 \n",
      " LR3 (LeakyReLU)             (None, 4, 4, 8)           0         \n",
      "                                                                 \n",
      " ct1 (Conv2DTranspose)       (None, 8, 8, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 16, 16, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " bn4 (BatchNormalization)    (None, 16, 16, 8)         32        \n",
      "                                                                 \n",
      " LR4 (LeakyReLU)             (None, 16, 16, 8)         0         \n",
      "                                                                 \n",
      " ct2 (Conv2DTranspose)       (None, 32, 32, 16)        1168      \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 64, 64, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " bn5 (BatchNormalization)    (None, 64, 64, 16)        64        \n",
      "                                                                 \n",
      " LR5 (LeakyReLU)             (None, 64, 64, 16)        0         \n",
      "                                                                 \n",
      " ct3 (Conv2DTranspose)       (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 128, 128, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " bn6 (BatchNormalization)    (None, 128, 128, 32)      128       \n",
      "                                                                 \n",
      " LR6 (LeakyReLU)             (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " ct4 (Conv2DTranspose)       (None, 128, 128, 1)       289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,233\n",
      "Trainable params: 13,009\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "\n",
    "    input = keras.Input(shape=(128,128,1), name='img')\n",
    "    #c1\n",
    "    encoded = keras.layers.Conv2D(32,kernel_size=kernel_size,strides=1,padding='same',name='c1')(input)\n",
    "    encoded = keras.layers.MaxPooling2D(pool_size=pool_size,strides=strides,padding='same')(encoded)\n",
    "    encoded = keras.layers.BatchNormalization(name='bn1')(encoded)\n",
    "    encoded = keras.layers.LeakyReLU(name='LR1')(encoded)\n",
    "\n",
    "    #c2\n",
    "    encoded = keras.layers.Conv2D(16,kernel_size=kernel_size,strides=2,padding='same',name='c2')(encoded)\n",
    "    encoded = keras.layers.MaxPooling2D(pool_size=pool_size,strides=strides,padding='same')(encoded)\n",
    "    encoded = keras.layers.BatchNormalization(name='bn2')(encoded)\n",
    "    encoded = keras.layers.LeakyReLU(name='LR2')(encoded)\n",
    "\n",
    "    #c3\n",
    "    encoded = keras.layers.Conv2D(8,kernel_size=kernel_size,strides=2,padding='same',name='c3')(encoded)\n",
    "    encoded = keras.layers.MaxPooling2D(pool_size=pool_size,strides=strides,padding='same')(encoded)\n",
    "    encoded = keras.layers.BatchNormalization(name='bn3')(encoded)\n",
    "    encoded = keras.layers.LeakyReLU(name='LR3')(encoded)\n",
    "\n",
    "\n",
    "\n",
    "    dencoded = keras.layers.Conv2DTranspose(8,kernel_size=kernel_size,strides=2,padding='same',name='ct1')(encoded)\n",
    "    dencoded = keras.layers.UpSampling2D(pool_size)(dencoded)\n",
    "    dencoded = keras.layers.BatchNormalization(name='bn4')(dencoded)\n",
    "    dencoded= keras.layers.LeakyReLU(name='LR4')(dencoded)\n",
    "\n",
    "    #c2\n",
    "    dencoded= keras.layers.Conv2DTranspose(16,kernel_size=kernel_size,strides=2,padding='same',name='ct2')(dencoded)\n",
    "    dencoded = keras.layers.UpSampling2D(pool_size)(dencoded)\n",
    "    dencoded= keras.layers.BatchNormalization(name='bn5')(dencoded)\n",
    "    dencoded= keras.layers.LeakyReLU(name='LR5')(dencoded)\n",
    "\n",
    "    #c3\n",
    "    dencoded= keras.layers.Conv2DTranspose(32,kernel_size=kernel_size,strides=1,padding='same',name='ct3')(dencoded)\n",
    "    dencoded = keras.layers.UpSampling2D(pool_size)(dencoded)\n",
    "    dencoded= keras.layers.BatchNormalization(name='bn6')(dencoded)\n",
    "    dencoded= keras.layers.LeakyReLU(name='LR6')(dencoded)\n",
    "\n",
    "    output = keras.layers.Conv2DTranspose(1,3,1,padding='same',activation='sigmoid',name='ct4')(dencoded)\n",
    "    autoencoder = tf.keras.Model(input,output)\n",
    "    \n",
    "    autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom loss function\n",
    "def SSIMLoss(y_true,y_pred):\n",
    "    return 1-tf.reduce_mean(tf.image.ssim(y_true,y_pred,1.0))\n",
    "\n",
    "#implement custom loss function\n",
    "autoencoder.compile(optimizer=optimizer, loss=SSIMLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 53s 936ms/step - loss: 0.6092 - val_loss: 0.4529\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 25s 602ms/step - loss: 0.3913 - val_loss: 0.4367\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 27s 639ms/step - loss: 0.3285 - val_loss: 0.4378\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 35s 845ms/step - loss: 0.2967 - val_loss: 0.4364\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 36s 859ms/step - loss: 0.2732 - val_loss: 0.4310\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 39s 933ms/step - loss: 0.2560 - val_loss: 0.4275\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 39s 930ms/step - loss: 0.2433 - val_loss: 0.4263\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 39s 920ms/step - loss: 0.2342 - val_loss: 0.4225\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 39s 923ms/step - loss: 0.2283 - val_loss: 0.4126\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 40s 945ms/step - loss: 0.2228 - val_loss: 0.3933\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 39s 928ms/step - loss: 0.2194 - val_loss: 0.3657\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 38s 917ms/step - loss: 0.2162 - val_loss: 0.3355\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 35s 836ms/step - loss: 0.2129 - val_loss: 0.3094\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 39s 936ms/step - loss: 0.2106 - val_loss: 0.2719\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 40s 943ms/step - loss: 0.2081 - val_loss: 0.2477\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 40s 944ms/step - loss: 0.2049 - val_loss: 0.2256\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 33s 798ms/step - loss: 0.2035 - val_loss: 0.2144\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 31s 737ms/step - loss: 0.1999 - val_loss: 0.2098\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 27s 637ms/step - loss: 0.1977 - val_loss: 0.2132\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 29s 691ms/step - loss: 0.1956 - val_loss: 0.2078\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    autoencoder.fit(\n",
    "    x=X_train,\n",
    "    y=X_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batchsize,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_test,X_test),\n",
    "    callbacks=[TensorBoard(log_dir='/tmp/autoencoder')]\n",
    "\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: autoencoder\\assets\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save('autoencoder')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "844750d5e47ed69586078e214d510ee037c49cfe135224478769d7a6fad57b7d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gpu_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
