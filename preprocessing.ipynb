{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt     \n",
    "import os \n",
    "from glob import glob\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocesser(object):\n",
    "\n",
    "    def __init__(self,files:list):\n",
    "        self.dices_raw = self.get_all_dices(files)\n",
    "        self.dices = self.convert_to_six(self.dices_raw)\n",
    "        \n",
    "    def get_training_data(self,file_array: list):\n",
    "        training_data = []\n",
    "   \n",
    "        #looping through files array\n",
    "        for file in file_array:\n",
    "            #getting the image data\n",
    "            image = tf.keras.utils.load_img(file, grayscale=False, color_mode='grayscale', target_size=None,interpolation='nearest')\n",
    "            #converting everything to numpy array\n",
    "            input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            input_arr = np.array([input_arr]) \n",
    "            #normalize the array to a float from 0 to 1\n",
    "            input_arr = input_arr/255\n",
    "            #add dice image to training data\n",
    "            training_data.append(input_arr[0])\n",
    "\n",
    "        dices_array = np.array(training_data)\n",
    "        return dices_array\n",
    "\n",
    "    \n",
    "    def get_all_dices(self,files: list):\n",
    "        dices = []\n",
    "        for file in files:\n",
    "            f = glob(file)\n",
    "            dices.append(self.get_training_data(f))\n",
    "        return dices\n",
    "\n",
    "    def convert_to_six(self, dices_raw:list):\n",
    "        dices = []\n",
    "        for i in range(7):\n",
    "            if i == 1:\n",
    "                temp = np.concatenate([dices_raw[i], dices_raw[i+1]])\n",
    "                dices.append(temp)\n",
    "                continue\n",
    "            if i ==2:\n",
    "                continue\n",
    "            if i == 3:\n",
    "                temp = np.concatenate([dices_raw[i], dices_raw[i+1]])\n",
    "                dices.append(temp)\n",
    "                continue\n",
    "            if i ==4:\n",
    "                continue\n",
    "            else:\n",
    "                dices.append(dices_raw[i])\n",
    "\n",
    "        t = np.concatenate([dices_raw[7],dices_raw[8]])\n",
    "\n",
    "        t= np.concatenate([t,dices_raw[9]])\n",
    "        t= np.concatenate([t,dices_raw[10]])\n",
    "        dices.append(t)\n",
    "        return dices\n",
    "\n",
    "    def normalize_samples(max_samples: int, dices: list):\n",
    "        #normalizing the amount of dices\n",
    "        _MAX_SAMPLES = max_samples\n",
    "        _dices = []\n",
    "        for dice in dices:\n",
    "            _dices.append(dice[:_MAX_SAMPLES])\n",
    "\n",
    "        _dices = np.array(_dices)\n",
    "\n",
    "        return _dices\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training_data(object):\n",
    "\n",
    "    files = ['./train_set/00/*','./train_set/01/*','./train_set/02/*','./train_set/03/*','./train_set/04/*','./train_set/05/*','./train_set/06/*','./train_set/07/*','./train_set/08/*','./train_set/09/*','./train_set/10/*'] \n",
    "    def __init__(self):\n",
    "        preprocessing = Preprocesser(self.files)\n",
    "        self.dices = preprocessing.dices\n",
    "        self.labels = self.get_labels(self.dices) \n",
    "        self.dices = self.stack_training_data(self.dices)\n",
    "        self.save_data(self.dices,'training_data.npy')\n",
    "        self.save_data(self.labels,'labels.npy')\n",
    "    \n",
    "\n",
    "    def save_data(self, data, name):\n",
    "\n",
    "        np.save(name,data)\n",
    "    #getting all the labels for this training\n",
    "    def get_labels(self,_dices):\n",
    "        labels = []\n",
    "        for i in range(len(_dices)):\n",
    "            for j in range(len(_dices[i])):\n",
    "                labels.append(i)\n",
    "        arr = np.array(labels)\n",
    "        arr = arr.reshape((-1,1))\n",
    "        return arr\n",
    "\n",
    "    def stack_training_data(self,_dices: list):\n",
    "        training_data = np.concatenate([_dices[0],_dices[1]])\n",
    "        for i in range(2,len(_dices)):\n",
    "            training_data = np.concatenate([training_data,_dices[i]])\n",
    "        return training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = Training_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "844750d5e47ed69586078e214d510ee037c49cfe135224478769d7a6fad57b7d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('gpu_tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
